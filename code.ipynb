# set working directory
setwd("/Users/sahra/Desktop/Data Analysis")

# install packages
# install.packages("readxl")
# install.packages("xtable")
# install.packages("tree")
# install.packages("e1071")
# install.packages("mlr")
# install.packages("class")
# install.packages("MASS") 
# install.packages("boot")
# install.packages("leaps")
# install.packages("RWeka")
# install.packagxes("ipred")
# install.packages("gbm")
# install.packages("C50")
# install.packages("bnlearn")
# install.packages("ROCR")
# install.packages("ISLR")
# install.packages("randomForest")
# install.packages("ggplot2")
# install.packages("rpart")
# install.packages("subselect")
# install.packages("glmnet")
# install.packages("kknn")
# install.packages("caret")
# install.packages("gglasso")
# install.packages("car")
# install.packages("neuralnet")
# cran <- getOption("repos")
# cran["dmlc"] <- "https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/"
# options(repos = cran)
# install.packages("mxnet")
# install.packages("adabag")
# install.packages("gam")
# install.packages("earth")
# install.packages("kernlab")

# execute code

source("V1.R")
setwd("/Users/sahra/Desktop/Data Analysis")
source("train_test_data.R")

train <- train_list[[1]]
test <- test_list[[1]]

\end{lstlisting}
\begin{lstlisting}
###########################################################
##########################V1.R############################
###########################################################
setwd("/Users/sahra/Desktop/Data Analysis/Data")

#------------------------------------------ read and clean data

# 1. read data
uncl_data = read.csv("testdata.csv", skip=1, stringsAsFactors = FALSE, na.strings="n/a")
# View(uncl_data)

# 2. generate table with number of NAs for variables with NAs and normal valuess
uncl_data_NAs = apply(uncl_data, 2, function (x) sum(is.na(x)))
number_NAs = sort(unique(uncl_data_NAs), decreasing = TRUE)
names_NAs = lapply(number_NAs[2:(length(number_NAs)-1)], function(x) names(uncl_data)[uncl_data_NAs==x])
table_NAs = data.frame(number_NAs[2:(length(number_NAs)-1)],Variable = character(length(number_NAs)-2))
table_NAs[,2] = sapply(1:length(names_NAs), function(i) paste(names_NAs[[i]], collapse = ','))
print(xtable::xtable(table_NAs), include.rownames=FALSE)

# 3. drop variables with too many NAs
uncl_data = uncl_data[,uncl_data_NAs<0.5*nrow(uncl_data)]

# 4. drop remaining non-explanatory variables
names(uncl_data)
var = c("loan_amnt", "int_rate", "purpose",  "sub_grade", "term",  "emp_length", "home_ownership", 
        "annual_inc", "verification_status", "loan_status", "addr_state", "delinq_2yrs",
        "inq_last_6mths", "open_acc", "pub_rec", "revol_util", "total_acc")
uncl_data = uncl_data[,(names(uncl_data) %in% var)]
# names(uncl_data)
# paste(names(uncl_data), collapse = ", ")

# 5. drop loans with any NAs
uncl_data_NAs_row = apply(uncl_data, 1, function (x) sum(is.na(x)))
uncl_data = uncl_data[uncl_data_NAs_row==0,]

# 6. clean variable values
uncl_data[1:nrow(uncl_data), 1:ncol(uncl_data)] = sapply(1:length(uncl_data), function(i) uncl_data[,i] = gsub(" ", "", uncl_data[,i], fixed = TRUE))

# charged_off
summary(uncl_data[,names(uncl_data)=="loan_status"]) # The remark "Does not meet the credit policy." 
  # implies that there was a policy change after loan was granted but before it was issued. 
uncl_data$charged_off = as.factor(as.numeric((uncl_data$loan_status=="ChargedOff")|(uncl_data$loan_status=="Doesnotmeetthecreditpolicy.Status:ChargedOff")))
uncl_data$loan_status = NULL

# sub_grades
data_sub_grades = sort(unique(uncl_data[,names(uncl_data)=="sub_grade"]))
uncl_data$sub_grade = as.numeric(plyr::mapvalues(uncl_data[,names(uncl_data)=="sub_grade"], from = data_sub_grades, to = 1:length(data_sub_grades)))
# sub_grade: 01 - A1,..., 35 - G5

# emp_lengths
data_emp_length = sort(unique(uncl_data$emp_length))
uncl_data$emp_length = as.numeric(plyr::mapvalues(uncl_data$emp_length, from = data_emp_length, to = c(10,1:9,0)))
# emp_length: <1 - 0, ..., >10 - 10

# continuous variables
con_var = c("loan_amnt", "annual_inc", "delinq_2yrs", "inq_last_6mths", "open_acc", "pub_rec", "total_acc")
uncl_data[,(names(uncl_data) %in% con_var)] = sapply(con_var, function(x) as.numeric(uncl_data[,names(uncl_data)==x]))

uncl_data$int_rate = as.numeric(substr(uncl_data$int_rate,1,nchar(uncl_data$int_rate)-1))/100
uncl_data$revol_util = as.numeric(substr(uncl_data$revol_util,1,nchar(uncl_data$revol_util)-1))/100

# term_36
uncl_data$term_36 = as.numeric(plyr::mapvalues(uncl_data$term, from = c("36months", "60months"), to = 1:0))
uncl_data$term = NULL

# verified
uncl_data$verified = as.numeric(plyr::mapvalues(uncl_data$verification_status, from = c("SourceVerified", "Verified", "NotVerified"), to = c(1,1,0)))
uncl_data$verification_status = NULL

# own_home and mortgage, default is RENT
uncl_data$own_home = as.numeric(uncl_data$home_ownership=="OWN")
uncl_data$mortgage = as.numeric(uncl_data$home_ownership=="MORTGAGE")
uncl_data$home_ownership = NULL

# purposes
uncl_data$for_ = uncl_data$purpose
uncl_data = cbind(uncl_data, model.matrix(~for_, uncl_data)[,2:length(unique(uncl_data$purpose))])
uncl_data$for_ = NULL
uncl_data$purpose = NULL

# states
uncl_data$st_ = uncl_data$addr_state
uncl_data = cbind(uncl_data, model.matrix(~st_, uncl_data)[,2:length(unique(uncl_data$addr_state))])
uncl_data$st_ = NULL
uncl_data$addr_state = NULL

# 7. again drop loans with any NAs
uncl_data_NAs_row = apply(uncl_data, 1, function (x) sum(is.na(x)))
uncl_data = uncl_data[uncl_data_NAs_row==0,]
nrow(uncl_data)

#------------------------------------------ normalise data
# normalise = function(x) return ((x - min(x)) / (max(x) - min(x))) 
# uncl_data[,-12] = as.data.frame(lapply(uncl_data[,-12], normalise))

#------------------------------------------ balance data
charged_off_loans = (uncl_data$charged_off==1)
fully_paid_loans = (uncl_data$charged_off==0)
sum(charged_off_loans)/sum(fully_paid_loans)
# Random Over-Sampling

#------------------------------------------ cleaned data
unbal_data = uncl_data
set.seed(1234)
data = rbind(unbal_data[fully_paid_loans,][sample(sum(fully_paid_loans),sum(charged_off_loans)),], unbal_data[charged_off_loans,])
# data_factors = uncl_data_factors

# generate table with description of variables
data_desc = readxl::read_excel("LCDataDictionary.xlsx")
print(xtable::xtable(data_desc), include.rownames=FALSE)

rm("charged_off_loans", "con_var", "data_emp_length", "data_sub_grades", "fully_paid_loans", "names_NAs", "number_NAs",  "table_NAs", "uncl_data", "uncl_data_NAs", "uncl_data_NAs_row", "var")

#------------------------------------------ test GBM on new data
pay <- ifelse(train$charged_off == 1, 1, 0)
train1 <- data.frame(train[,names(train)%in%setdiff(names(test),c("charged_off"))], pay)
gbm <- gbm::gbm(pay~., data = train1, n.trees = 450, interaction.depth = 4, shrinkage = 0.01, verbose = F)
MER <- mean(as.numeric(predict(gbm, newdata = test, n.trees = 450, type="response")>0.5)!=test$charged_off)
typeI <-  sum((predict(gbm, newdata = test, n.trees = 450, type="response")>.5)==FALSE & test$charged_off==1)/sum(test$charged_off==1)
typeII <-  sum((predict(gbm, newdata = test, n.trees = 450, type="response")>.5)==TRUE & test$charged_off==0)/sum(test$charged_off==0)
gbm::gbm.roc.area(as.numeric(test$charged_off),predict(gbm, newdata = test, n.trees = 450, type="response"))
\end{lstlisting}
\begin{lstlisting}
##########################################################
######################train_test.R########################
##########################################################
# define training and testing data
set.seed(1234)

# try 60-40, 70-30, 80-20 splits
ran_sample = lapply(c(0.6,0.7,0.8), function(x) sample(nrow(data), floor(x*nrow(data))))
train_simple = lapply(1:length(ran_sample), function(x) data[ran_sample[[x]],])
test_simple = lapply(1:length(ran_sample), function(x) data[-ran_sample[[x]],])

# try 10- and 5-fold CV
ran_sample = sample(nrow(data))
k = 10
k_sample_size = floor(nrow(data)/k)
train_cv_10 = lapply(1:k, function(x) data[ran_sample[(x-1)*k_sample_size+(1:k_sample_size)],])
test_cv_10 = lapply(1:k, function(x) data[-(ran_sample[(x-1)*k_sample_size+(1:k_sample_size)]),])
k = 5
k_sample_size = floor(nrow(data)/k)
train_cv_5 = lapply(1:k, function(x) data[ran_sample[(x-1)*k_sample_size+(1:k_sample_size)],])
test_cv_5 = lapply(1:k, function(x) data[-(ran_sample[(x-1)*k_sample_size+(1:k_sample_size)]),])

train_list = c(train_simple, train_cv_10, train_cv_5)
test_list = c(test_simple, test_cv_10, test_cv_5)
remove("k","k_sample_size", "train_simple", "test_simple", "train_cv_10", "train_cv_5", "test_cv_10", "test_cv_5", "ran_sample")
\end{lstlisting}

\begin{lstlisting}
##########################################################
########################adaboost.R########################
##########################################################
size = setdiff(seq(50,by=50,length=11),100)
names = c("SAMME", "Ada_boost Breiman", "Ada_boost Freund, n=100", paste0("Ada_boost Freund, n=",size))
MERs = data.frame(matrix(1,length(train_list),length(names)))
colnames(MERs) = names
typeI = data.frame(matrix(0,length(train_list),length(names))) # charged off loans wrongly classified
colnames(typeI) = names 
typeII = data.frame(matrix(0,length(train_list),length(names))) # fully paid loans wrongly classified
colnames(typeII) = names


for(i in 2:length(train_list)){
  
  # set train and test data
  train = train_list[[i]]
  test = test_list[[i]]
  f = as.formula(paste('charged_off ~', paste(colnames(train)[setdiff(1:length(train),c(12))], collapse='+')))
  
  adaboost = adabag::boosting(charged_off~., train ) #, mfinal = 5000
  ada_pred = adabag::predict.boosting(adaboost, newdata=test)
  MERs[i,2] = mean(as.numeric(ada_pred$class)!= test$charged_off)
  typeI[i,2] = mean(as.numeric(ada_pred$class)==0 & test$charged_off==1)
  typeII[i,2] = mean(as.numeric(ada_pred$class)==1 & test$charged_off==0)
  
  adaboost = adabag::boosting(charged_off~., train, coeflearn="Zhu" ) #, mfinal = 5000
  ada_pred = adabag::predict.boosting(adaboost, newdata=test)
  MERs[i,1] = mean(as.numeric(ada_pred$class)!= test$charged_off)
  typeI[i,1] = mean(as.numeric(ada_pred$class)==0 & test$charged_off==1)
  typeII[i,1] = mean(as.numeric(ada_pred$class)==1 & test$charged_off==0)
  
  adaboost = adabag::boosting(charged_off~., train, coeflearn="Freund" ) #, mfinal = 5000
  ada_pred = adabag::predict.boosting(adaboost, newdata=test)
  MERs[i,3] = mean(as.numeric(ada_pred$class)!= test$charged_off)
  typeI[i,3] = mean(as.numeric(ada_pred$class)==0 & test$charged_off==1)
  typeII[i,3] = mean(as.numeric(ada_pred$class)==1 & test$charged_off==0)
  
  ada_pred = sapply(size, function(x) adabag::predict.boosting(adabag::boosting(charged_off~., train, coeflearn="Freund", mfinal = x), newdata=test)) #, mfinal = 5000
  MERs[i,4:13] = apply(ada_pred, 2, function(x) mean(as.numeric(x$class)!= test$charged_off))
  typeI[i,4:13] = apply(ada_pred, 2, function(x) mean(as.numeric(x$class)==0 & test$charged_off==1))
  typeII[i,4:13] = apply(ada_pred, 2, function(x) mean(as.numeric(x$class)==1 & test$charged_off==0))
  
}

saveRDS(MERs, "ada_MERs")
saveRDS(typeI, "ada_typeI")
saveRDS(typeII, "ada_typeII")

print(xtable::xtable(MERs), include.rownames=FALSE)
print(xtable::xtable(typeI), include.rownames=FALSE)
print(xtable::xtable(typeII), include.rownames=FALSE)


\end{lstlisting}

\begin{lstlisting}
##########################################################
#############################da.R#########################
##########################################################
names = c("LDA", "LDA Gaussian", "QDA Gaussian", paste0("LDA, k=",2:10))
MERs = data.frame(matrix(0,length(train_list),length(names)))
colnames(MERs) = names
typeI = data.frame(matrix(0,length(train_list),length(names))) # charged off loans wrongly classified
colnames(typeI) = names 
typeII = data.frame(matrix(0,length(train_list),length(names))) # fully paid loans wrongly classified
colnames(typeII) = names

par(mfrow=c(5,2))
p_value <- numeric(11)
for(i in setdiff(1:11,9)) {
  car::qqPlot(data[,i], "norm", ylim=c(0,1), ylab=paste0(names(data)[i]))
  p_value[i] <- shapiro.test(data[1:5000,i])$p.value
}
par(mfrow=c(1,1))

for(i in 1:length(train_list)){
  
  # set train and test data
  train = train_list[[i]]
  test = test_list[[i]]
  
  f <- as.formula(paste('charged_off ~', paste(colnames(train)[setdiff(1:length(train),c(12,30:length(data)))], collapse='+')))
  
  # lda 
  lda_fit = MASS::lda(f, data = train)
  lda_pred = predict(lda_fit, test)$class
  MERs[i,1] = mean(lda_pred!=test$charged_off)
  typeI[i,1] = mean(lda_pred==0 & test$charged_off==1)
  typeII[i,1] = mean(lda_pred==1 & test$charged_off==0)
  
  f <- as.formula(paste('charged_off ~', paste(colnames(train)[setdiff(1:length(train),c(12:length(data)))], collapse='+')))
  
  # lda GAUSSIAN
  lda_fit = MASS::lda(f, data = train)
  lda_pred = predict(lda_fit, test)$class
  MERs[i,2] = mean(lda_pred!=test$charged_off)
  typeI[i,2] = mean(lda_pred==0 & test$charged_off==1)
  typeII[i,2] = mean(lda_pred==1 & test$charged_off==0)

  # qda GAUSSIAN
  qda_fit = MASS::qda(f, data = train)
  qda_pred = predict(qda_fit, test)$class
  MERs[i,3] = mean(qda_pred!=test$charged_off)
  typeI[i,3] = mean(qda_pred==0 & test$charged_off==1)
  typeII[i,3] = mean(qda_pred==1 & test$charged_off==0)
  
  # lda subselect 
  lda_mat = subselect::ldaHmat(train[,1:11], train$charged_off)
  lda_sets = subselect::improve(lda_mat$mat, kmin=2, kmax=10)$bestsets
  for(k in 2:10){
    f <- as.formula(paste('charged_off ~', paste(colnames(train)[lda_sets[k-1,1:k]], collapse='+')))
    lda_fit = MASS::lda(f, data = train)
    lda_pred = predict(lda_fit, test)$class
    MERs[i,2+k] = mean(lda_pred!=test$charged_off)
    typeI[i,2+k] = mean(lda_pred==0 & test$charged_off==1)
    typeII[i,2+k] = mean(lda_pred==1 & test$charged_off==0)
  }
} 

saveRDS(MERs, "da_MERs")
saveRDS(typeI, "da_typeI")
saveRDS(typeII, "da_typeII")

print(xtable::xtable(MERs), include.rownames=FALSE)
print(xtable::xtable(typeI), include.rownames=FALSE)
print(xtable::xtable(typeII), include.rownames=FALSE)

\end{lstlisting}

\begin{lstlisting}
##########################################################
#########################gam.R############################
##########################################################
names = c("GAM wo s", paste0("GAM, s=", names(data)[1:11]))
MERs = data.frame(matrix(1,length(train_list),length(names)))
colnames(MERs) = names
typeI = data.frame(matrix(0,length(train_list),length(names))) # charged off loans wrongly classified
colnames(typeI) = names 
typeII = data.frame(matrix(0,length(train_list),length(names))) # fully paid loans wrongly classified
colnames(typeII) = names


for(i in 1:length(train_list)){
  
  # set train and test data
  train = train_list[[i]]
  test = test_list[[i]]
  # f = as.formula(paste('charged_off ~', paste(colnames(train)[13:29], collapse='+'), "+ s(" paste(colnames(train)[1:11], collapse=', df=6)+')))
  
  f = as.formula(paste('charged_off ~', paste(colnames(train)[1:length(train)], collapse='+')))
  logitgam = gam::gam(f , data = train, family = binomial)
  logit_pred <- as.numeric(predict(logitgam, newdata=test)>0.5)
  MERs[i,1] = mean(logit_pred!=test$charged_off)
  typeI[i,1] = mean(logit_pred==0 & test$charged_off==1)
  typeII[i,1] = mean(logit_pred==1 & test$charged_off==0)
  
  logit_pred = sapply(1:11, function(x){
    as.numeric(predict(
      gam::gam(as.formula(paste('charged_off ~ s(', colnames(train)[i], ", df=6) +", paste(colnames(train)[setdiff(1:length(train),i)], collapse='+'))) , data = train, family = binomial),
      logitgam, newdata=test
    )>0.5)
  })
  MERs[i,2:12] = apply(logit_pred, function(x) mean(x!= test$charged_off))
  typeI[i,2:12] = apply(logit_pred, function(x) mean(x==0 & test$charged_off==1))
  typeII[i,2:12] = apply(logit_pred, function(x) mean(x==1 & test$charged_off==0))
  
}

saveRDS(MERs, "gam_MERs")
saveRDS(typeI, "gam_typeI")
saveRDS(typeII, "gam_typeII")

print(xtable::xtable(MERs), include.rownames=FALSE)
print(xtable::xtable(typeI), include.rownames=FALSE)
print(xtable::xtable(typeII), include.rownames=FALSE)

\end{lstlisting}

\begin{lstlisting}
##########################################################
#########################NB_knn.R#########################
##########################################################
# library("ISLR")

names = c("NB", paste0("kNN, k=",1:10), paste0("weighted kNN, k=",1:10))
MERs = data.frame(matrix(0,length(train_list),length(names)))
colnames(MERs) = names
typeI = data.frame(matrix(0,length(train_list),length(names))) # charged off loans wrongly classified
colnames(typeI) = names 
typeII = data.frame(matrix(0,length(train_list),length(names))) # fully paid loans wrongly classified
colnames(typeII) = names

set.seed(1234)
for(i in 1:length(train_list)){
  
  # set train and test data
  train = train_list[[i]]
  test = test_list[[i]]
  
  # naive Bayes model
  Naive_Bayes_Model = e1071::naiveBayes(as.factor(train$charged_off)~., data=train)
  nb_pred = predict(Naive_Bayes_Model, test)
  MERs[i,1] = mean(nb_pred!=test$charged_off)
  typeI[i,1] = mean(nb_pred==0 & test$charged_off==1)
  typeII[i,1] = mean(nb_pred==1 & test$charged_off==0)
  
  # kNN 
  # try different k, plot misclassification rate against 1/k k = 1,....,10
  kNN_pred = sapply(1:10, function(x) class::knn(train[,-12], test[,-12], train$charged_off, k = x))
  MERs[i,2:11] = apply(kNN_pred, 2, function(x) mean(x!=test$charged_off))
  typeI[i,2:11] = apply(kNN_pred, 2, function(x) mean(x==0 & test$charged_off==1))
  typeII[i,2:11] = apply(kNN_pred, 2, function(x) mean(x==1 & test$charged_off==0))
  
  # weighted kNN using epanechnikov kernel
  kNN_pred = sapply(1:10, function(x) fitted(kknn::kknn(as.factor(charged_off)~., train, test, distance = 1, k = x, kernel ="epanechnikov")))
  MERs[i,12:21] = apply(kNN_pred, 2, function(x) mean(x!=test$charged_off))
  typeI[i,12:21] = apply(kNN_pred, 2, function(x) mean(x==0 & test$charged_off==1))
  typeII[i,12:21] = apply(kNN_pred, 2, function(x) mean(x==1 & test$charged_off==0))
  
}

saveRDS(MERs, "NB_kNN_Bayes_MERs")
saveRDS(typeI, "NB_kNN_Bayes_typeI")
saveRDS(typeII, "NB_kNN_Bayes_typeII")

print(xtable::xtable(MERs), include.rownames=FALSE)
print(xtable::xtable(typeI), include.rownames=FALSE)
print(xtable::xtable(typeII), include.rownames=FALSE)

\end{lstlisting}

\begin{lstlisting}
##########################################################
########################neuralnet.R#######################
##########################################################
hlayers = list(0,c(3,3), c(15,5), c(10,10), c(5,10), c(4,5,3))
names = c(paste0("NN, hidden=",hlayers))
MERs = data.frame(matrix(1,length(train_list),length(names)))
colnames(MERs) = names
typeI = data.frame(matrix(0,length(train_list),length(names))) # charged off loans wrongly classified
colnames(typeI) = names 
typeII = data.frame(matrix(0,length(train_list),length(names))) # fully paid loans wrongly classified
colnames(typeII) = names

library(neuralnet)
fixInNamespace("calculate.neuralnet", pos="package:neuralnet") # commenting linews 65 and 66

for(i in 1:length(train_list)){
  
  # set train and test data
  train = train_list[[i]]
  test = test_list[[i]]
  
  #f <- as.formula(paste('charged_off ~', paste(colnames(train)[setdiff(2:length(train),c(12))], collapse='+')))
  f <- as.formula(paste('charged_off ~', paste(colnames(train)[setdiff(1:29,c(12))], collapse='+')))
  train1 <- data.matrix(train)
  train1[,12] <- train1[,12] - 1
  nn <- matrix(0,nrow(test),length(hlayers))
  for(i in 1:length(hlayers)){
    nn[,i] <- neuralnet::compute(neuralnet::neuralnet(f,data=train1,hidden=hlayers[[i]],linear.output=FALSE, threshold=0.01, rep=3),data.matrix(test[,colnames(train)[setdiff(1:29,c(12))]]))$net.result
  }
  MERs[i,1:length(hlayers)] = apply(nn, 2, function(x) mean(as.numeric(x>0.5)!= test$charged_off))
  typeI[i,1:length(hlayers)] = apply(nn, 2, function(x) mean(as.numeric(x>0.5)==0 & test$charged_off==1))
  typeII[i,1:length(hlayers)] = apply(nn, 2, function(x) mean(as.numeric(x>0.5)==1 & test$charged_off==0))
}

plot(nn)

saveRDS(MERs, "nn_MERs")
saveRDS(typeI, "nn_typeI")
saveRDS(typeII, "nn_typeII")

print(xtable::xtable(MERs), include.rownames=FALSE)
print(xtable::xtable(typeI), include.rownames=FALSE)
print(xtable::xtable(typeII), include.rownames=FALSE)


\end{lstlisting}

\begin{lstlisting}
##########################################################
#########################present.R########################
##########################################################
setwd("/Users/sahra/Desktop/Data Analysis")

a <- "svm"
MERs <- readRDS(paste0(a, "_MERs"))
typeI <- readRDS(paste0(a, "_typeI"))
typeII <- readRDS(paste0(a, "_typeII"))

all <- data.frame()
new <- cbind(names(MERs), round(as.numeric(apply(MERs,2,mean)),4),  round(as.numeric(apply(typeI,2,mean)),4),  round(as.numeric(apply(typeII,2,mean)),4))
all = rbind(all[1:nrow(all),],new)
names(all) <- c("Approach", "MER", "Type I error", "Type II error")
print(xtable::xtable(all), include.rownames=FALSE)

\end{lstlisting}

\begin{lstlisting}
##########################################################
########################regression.R######################
##########################################################
names = c("logit", "probit", "logit_poly", "probit_poly", "glmnet ada_lasso", "group_lasso", paste0("glmnet, alpha=",seq(0,1,0.1)), paste0("glmnet poly, alpha=", seq(0,1,0.2)))
MERs = data.frame(matrix(1,length(train_list),length(names)))
colnames(MERs) = names
typeI = data.frame(matrix(1,length(train_list),length(names))) # charged off loans wrongly classified
colnames(typeI) = names 
typeII = data.frame(matrix(1,length(train_list),length(names))) # fully paid loans wrongly classified
colnames(typeII) = names
TH = data.frame(matrix(1,length(train_list),length(names)))
colnames(TH) = names
set.seed(1234)

# cv lambda for linear formula
x <- model.matrix(charged_off~., data)
lambda1 <- sapply(0:10, function(alpha) glmnet::cv.glmnet(x, data$charged_off, family="binomial", alpha=alpha)$lambda.1se)
plot(glmnet::cv.glmnet(x, data$charged_off, family="binomial", alpha=0.1))

# group lasso lambda
group_lambda = gglasso::cv.gglasso(x[,-12], plyr::mapvalues(as.numeric(data$charged_off), c(1,2), c(-1,1)), group=c(1:13,14,14,rep(15,13), rep(16,49)), pred.loss = "misclass", nfolds=10, loss="logit")$lambda.1se

# Rates for adaptive lasso
# Ridge Regression to create adaptive weights
cv.ridge <- glmnet::cv.glmnet(x, data$charged_off, family='binomial', alpha=0, parallel=TRUE, standardize=TRUE)
w3 <- 1/abs(matrix(coef(cv.ridge, s=cv.ridge$lambda.min) [, 1][2:(ncol(x)+1)] ))^1 ## Using gamma = 1
w3[w3[,1] == Inf] <- 999999999 ## Replacing values estimated as Infinite for 999999999

# Adaptive Lasso
cv.lasso <- glmnet::cv.glmnet(x, data$charged_off, family='binomial', alpha=1, parallel=TRUE, standardize=TRUE, type.measure='class', penalty.factor=w3)
plot(cv.lasso)
plot(cv.lasso$glmnet.fit, xvar="lambda", label=TRUE)
abline(v = log(cv.lasso$lambda.min))
abline(v = log(cv.lasso$lambda.1se))
coef(cv.lasso, s=cv.lasso$lambda.1se)
coef <- coef(cv.lasso, s='lambda.1se')

# cv lambda for polynomial formula up to degree 3
not_binary <- c("annual_inc", "emp_length", "delinq_2yrs", "inq_last_6mths", "int_rate", "loan_amnt", "open_acc", "revol_util", "sub_grade", "total_acc")
data1 = cbind(data$charged_off,data[,names(data) %in% not_binary], data[, names(data) %in% not_binary]^2, data[, names(data) %in% not_binary]^3)
colnames(data1) = c("charged_off",not_binary, paste0(not_binary, "2"), paste0(not_binary, "3"))
x <- model.matrix(charged_off~., data1)
lambda2 <- sapply(seq(0,1,0.2), function(alpha) glmnet::cv.glmnet(x, data$charged_off, family="binomial", alpha=alpha)$lambda.1se)

for(i in 1:length(train_list)){
  
  # set train and test data
  train = train_list[[i]]
  test = test_list[[i]]
  
  f <- as.formula(paste('charged_off ~', paste(colnames(train)[setdiff(1:length(train),12)], collapse='+')))
  
  # logistic regression
  glm_fit = glm(f, data = train, family=binomial(link="logit")) # glm_fit = glm(train$charged_off ~ train$loan_amnt + train$term + train$int_rate + train$int_rate + train$sub_grade + train$, data = Smarket, family = binomial)
  glm_probs = predict(glm_fit, test, type = "response")
  for(th in seq(0.3,0.7,0.01)){
    glm_pred = rep(0, nrow(test))
    glm_pred[glm_probs > th] = 1
    if(mean(glm_pred!=test$charged_off)<MERs[i,1]){
      TH[i,1] = th
      MERs[i,1] = mean(glm_pred!=test$charged_off)
      typeI[i,1] = mean(glm_pred==0 & test$charged_off==1)
      typeII[i,1] = mean(glm_pred==1 & test$charged_off==0)
    }
  }
  
  # probabilistic regression
  glm_fit = glm(f, data = train, family=binomial(link="probit")) # glm_fit = glm(train$charged_off ~ train$loan_amnt + train$term + train$int_rate + train$int_rate + train$sub_grade + train$, data = Smarket, family = binomial)
  glm_probs = predict(glm_fit, test, type = "response")
  for(th in seq(0.3,0.7,0.01)){
    glm_pred = rep(0, nrow(test))
    glm_pred[glm_probs > th] = 1
    if(mean(glm_pred!=test$charged_off)<MERs[i,2]){
      TH[i,2] = th
      MERs[i,2] = mean(glm_pred!=test$charged_off)
      typeI[i,2] = mean(glm_pred==0 & test$charged_off==1)
      typeII[i,2] = mean(glm_pred==1 & test$charged_off==0)
    }
  }
  
  f <- as.formula(paste('charged_off ~', paste(setdiff(colnames(train), c("charged_off", not_binary)), collapse='+'), "+", paste("poly(", not_binary,",3)", collapse='+')))
  
  # logistic regression
  glm_fit = glm(f, data = train, family=binomial(link="logit")) # glm_fit = glm(train$charged_off ~ train$loan_amnt + train$term + train$int_rate + train$int_rate + train$sub_grade + train$, data = Smarket, family = binomial)
  glm_probs = predict(glm_fit, test, type = "response")
  for(th in seq(0.3,0.7,0.01)){
    glm_pred = rep(0, nrow(test))
    glm_pred[glm_probs > th] = 1
    if(mean(glm_pred!=test$charged_off)<MERs[i,3]){
      TH[i,3] = th
      MERs[i,3] = mean(glm_pred!=test$charged_off)
      typeI[i,3] = mean(glm_pred==0 & test$charged_off==1)
      typeII[i,3] = mean(glm_pred==1 & test$charged_off==0)
    }
  }
  
  # probabilistic regression
  glm_fit = glm(f, data = train, family=binomial(link="probit")) # glm_fit = glm(train$charged_off ~ train$loan_amnt + train$term + train$int_rate + train$int_rate + train$sub_grade + train$, data = Smarket, family = binomial)
  glm_probs = predict(glm_fit, test, type = "response")
  for(th in seq(0.3,0.7,0.01)){
    glm_pred = rep(0, nrow(test))
    glm_pred[glm_probs > th] = 1
    if(mean(glm_pred!=test$charged_off)<MERs[i,4]){
      TH[i,4] = th
      MERs[i,4] = mean(glm_pred!=test$charged_off)
      typeI[i,4] = mean(glm_pred==0 & test$charged_off==1)
      typeII[i,4] = mean(glm_pred==1 & test$charged_off==0)
    }
  }
  
  # glmnet adalasso
  x_train <- model.matrix(charged_off~., train)
  x_test = model.matrix(charged_off~., test)
  glm_probs = predict(cv.lasso$glmnet.fit, newx = x_test, s = cv.lasso$lambda.1se)
  for(th in seq(0.3,0.7,0.01)){
    glm_pred = rep(0, nrow(test))
    glm_pred[glm_probs > th] = 1
    if(mean(glm_pred!=test$charged_off)<MERs[i,5]){
      TH[i,5] = th 
      MERs[i,5] = mean(glm_pred!=test$charged_off)
      typeI[i,5] = mean(glm_pred==0 & test$charged_off==1)
      typeII[i,5] = mean(glm_pred==1 & test$charged_off==0)
    }
  }
  
  # group lasso
  glm_probs = predict(gglasso::gglasso(x=x_train[,-12],y=plyr::mapvalues(as.numeric(train$charged_off), c(1,2), c(-1,1)),group=c(1:13,14,14,rep(15,13), rep(16,49)),loss="logit"), newx = x_test[,-12], s =  group_lambda)
  for(th in seq(0.3,0.7,0.01)){
    glm_pred = rep(0, nrow(test))
    glm_pred[glm_probs > th] = 1
    if(mean(glm_pred!=test$charged_off)<MERs[i,5]){
      TH[i,6] = th 
      MERs[i,6] = mean(glm_pred!=test$charged_off)
      typeI[i,6] = mean(glm_pred==0 & test$charged_off==1)
      typeII[i,6] = mean(glm_pred==1 & test$charged_off==0)
    }
  }
  
  # glmnet 
  glm_probs = sapply(0:10, function(x) predict(glmnet::glmnet(x_train, train$charged_off, alpha=x/10, lambda=lambda1[x+1] ,family="binomial"), newx = x_test))
  glm_pred = matrix(0, nrow(test), 11)
  for(th in seq(0.3,0.7,0.01)){
    glm_pred = matrix(0, nrow(test), 11)
    for (k in 1:11) {
      for (j in 1:nrow(test)){
        if(glm_probs[j,k]>th) glm_pred[j,k] = 1
      }
    }
    if(mean(apply(glm_probs, 2, function(x) mean(as.integer(x>th)!=test$charged_off)))<mean(as.numeric(MERs[i,6:16]))){
      TH[i,7:17] = th
      MERs[i,7:17] = apply(glm_probs, 2, function(x) mean(as.integer(x>th)!=test$charged_off))
      typeI[i,7:17] = apply(glm_pred, 2, function(x) mean(as.integer(x>th)==0 & test$charged_off==1))
      typeII[i,7:17] = apply(glm_pred, 2, function(x) mean(as.integer(x>th)==1 & test$charged_off==0))
    }
  }
  
  # glmnet poly
  train = cbind(train$charged_off,train[, names(data) %in% not_binary], train[, names(data) %in% not_binary]^2, train[, names(data) %in% not_binary]^3)
  colnames(train) = c("charged_off",not_binary, paste0(not_binary, "2"), paste0(not_binary, "3"))
  x_train <- model.matrix(charged_off~., train)
  test = cbind(test$charged_off,test[, names(data) %in% not_binary], test[, names(data) %in% not_binary]^2, test[, names(data) %in% not_binary]^3)
  colnames(test) = c("charged_off",not_binary, paste0(not_binary, "2"), paste0(not_binary, "3"))
  x_test = model.matrix(charged_off~., test)
  glm_probs = sapply(seq(0,1,0.2), function(x) predict(glmnet::glmnet(x_train, train$charged_off, alpha=x, lambda=lambda2[x*5+1] ,family="binomial"), newx = x_test))
  glm_pred = matrix(0, nrow(test), length(seq(0,1,0.2)))
  for(th in seq(0.3,0.7,0.01)){
    for (k in 1:length(seq(0,1,0.2))) {
      for (j in 1:nrow(test)){
        if(glm_probs[j,k]>th) glm_pred[j,k] = 1
      }
    }
    if(mean(apply(glm_probs, 2, function(x) mean(as.integer(x>th)!=test$charged_off)))<mean(as.numeric(MERs[i,16+ 1:length(seq(0,1,0.2))]))){
      TH[i, 16+ 1:length(seq(0,1,0.2))] = rep(th, length(seq(0,1,0.2)))
      MERs[i,16+ 1:length(seq(0,1,0.2))] = apply(glm_probs, 2, function(x) mean(as.integer(x>th)!=test$charged_off))
      typeI[i,16+ 1:length(seq(0,1,0.2))] = apply(glm_pred, 2, function(x) mean(as.integer(x>th)==0 & test$charged_off==1))
      typeII[i,16+ 1:length(seq(0,1,0.2))] = apply(glm_pred, 2, function(x) mean(as.integer(x>th)==1 & test$charged_off==0))
    }
  }
} 

saveRDS(MERs, "regr_MERs")
saveRDS(typeI, "regr_typeI")
saveRDS(typeII, "regr_typeII")

print(xtable::xtable(MERs), include.rownames=FALSE)
print(xtable::xtable(typeI), include.rownames=FALSE)
print(xtable::xtable(typeII), include.rownames=FALSE)
